{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOF\n",
      "['b'\\xd2\\x1d9\\xfa\\x00P\\x0f\\x13I\\x9a\\xf89\\x06'', count: 16889, 'b'E.\\x1c)\\xa4\\xb2\\x89\\xb6\\x06\\xba\\xd2\\xad\\x06'', count: 11647, 'b'V+x\\xe8\\x00Po\\xcd\\xe4\\xde\\xccw\\x06'', count: 10114, 'b'\\xb7\\xf6h\\xd0\\xc1\\x8b+\\xfc\\xe1\\x08\\x00P\\x06'', count: 9118, 'b'\\x01l|\\xff\\x8f\\r\\x01l\\xc5\\xc8\\x01\\xbb\\x06'', count: 8600, 'b'\\x99\\xc1\\xe9Z\\x00P+\\xfc\\xe0=\\xe7%\\x06'', count: 8171, 'b'\\xd2\\x1e\\xbeu\\x01\\xbb+\\xfc\\xe0.\\x92\\xd5\\x06'', count: 6513, 'b'c\\x0f\\xb2\\xd4\\x80\\xd2\\x01`\\x8d\\x12\\x01\\xbb\\x06'', count: 6446, 'b'\\x01l|\\xec\\xcc\\x1b\\x01l\\xc5\\xc8\\x01\\xbb\\x06'', count: 5422, 'b'E\\x0c\\xd5\\xf7\\xd7(\\xdd.\\xdc\\xec\\x00P\\x06'', count: 5316, 'b'E\\x0c\\xd5\\xf5\\xa4\\x14\\xdd.\\xdc\\xec\\x00P\\x06'', count: 5256, 'b'OZ\\x0e\\xae\\xdc\\xf1o\\xcd\\x19\\xf0\\x1f\\x90\\x11'', count: 5141, 'b'\\x99\\xc1\\x8f\\x05\\x00P+\\xfc\\xe2#\\xa0W\\x06'', count: 5139, 'b'E\\x0c\\xd1K\\x85\\xf6\\xdd.\\xdc\\xf2\\x00P\\x06'', count: 5036, 'b'\\x99\\xc1\\x96\\xcf\\x00P\\x99\\xc1.\\xe0\\xdf\\xc6\\x06'', count: 4879, 'b'\\x01l|\\xecJ\\x97\\x01l\\xc3i\\x01\\xbb\\x06'', count: 4828, 'b'E\\x16\\xd7\\xb1\\x01\\xbbg\\xaa\\xc7\\xee\\xee\\xa5\\x06'', count: 4663, 'b'+\\xf05,\\x00P\\x99\\xc1\\x08a\\xc2A\\x06'', count: 4522, 'b'~b0\\x96\\xf2F+\\xfc\\xe2\\x07\\x00P\\x06'', count: 4501, 'b'\\xd3C\\xb9G\\xde\\x95+\\x93\\xc9H\\x01\\xbb\\x06'', count: 4493] 650\n",
      "Total memory 5496 bytes :Top-650 with size 5496 bytes.\n",
      "Execution time:567.8287053108215 seconds.\n",
      "Find:188, TP:188, FP:462\n",
      "Precision:   0.2892\n",
      "ARE: 0.596169\n",
      "AAE: 599.296923\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import operator\n",
    "import pandas as pd\n",
    "\n",
    "class Node():\n",
    "    def __init__(self,count=0):\n",
    "        self.count=count\n",
    "    def add_count(self,count=1):\n",
    "        self.count+=count\n",
    "    def __str__(self):\n",
    "        return 'ID: {}, count: {}'.format(self.ID,self.count)\n",
    "    def __repr__(self):\n",
    "        return ''\n",
    "\n",
    "class Head(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.distinct = hyperloglog.HyperLogLog(0.01)\n",
    "    def __str__(self):\n",
    "        return 'total count: {}, distinct element: {}'.format(self.count,len(self.distinct))\n",
    "    def __repr__(self):\n",
    "        return '[count: {}, distinct: {}]'.format(self.count,len(self.distinct))\n",
    "\n",
    "class Tail(Node):\n",
    "    def __init__(self,ID,count):\n",
    "        self.ID = ID\n",
    "        super().__init__(count)\n",
    "    def __str__(self):\n",
    "        return 'ID: {}, count: {}'.format(self.ID,self.count)\n",
    "    def __repr__(self):\n",
    "        return \"'{}', count: {}\".format(self.ID,self.count)\n",
    "\n",
    "def find(e,element_list):\n",
    "    try:\n",
    "        index = [ele.ID for ele in element_list].index(e.ID)\n",
    "    except:\n",
    "        index=-99\n",
    "    return index  \n",
    "    \n",
    "    \n",
    "start=time.time()\n",
    "\n",
    "filename='caida_0.dat'\n",
    "filepath=\"..\\\\dataset\\\\\"\n",
    "src_data=os.path.join(filepath,filename)\n",
    "\n",
    "size=650\n",
    "Top=[]\n",
    "#item_count=100000\n",
    "\n",
    "with open(src_data,'rb') as file:\n",
    "     #以binary讀取，資料型態也為byte\n",
    "    while True:\n",
    "        e=str(file.read(13))\n",
    "        if len(e)<13:\n",
    "            print('EOF')\n",
    "            break\n",
    "        else:\n",
    "            item=Tail(e,1)\n",
    "            #item_count-=1\n",
    "            # print(\"read {}th element: {}\".format(item_count,element))\n",
    "            if len(Top)==0:\n",
    "                Top.append(item)\n",
    "            else:\n",
    "                index=find(item,Top)\n",
    "                if index<0:\n",
    "                    if len(Top)<size:\n",
    "                        Top.append(item)\n",
    "                    else:\n",
    "                        # replace last element with count \n",
    "                        Top[-1].ID=item.ID\n",
    "                        Top[-1].count+=1\n",
    "                else:\n",
    "                    Top[index].count+=1\n",
    "            Top.sort(key=operator.attrgetter('count'),reverse=True)\n",
    "\n",
    "end=time.time()\n",
    "print(Top[:20],len(Top))\n",
    "print(\"Total memory {0} bytes :Top-{1} with size {0} bytes.\".format(sys.getsizeof(Top),size))\n",
    "print(\"Execution time:{} seconds.\".format(str(end-start)))\n",
    "\n",
    "\n",
    "#====================result tocsv=============================\n",
    "templi=[[i.ID,i.count] for i in Top]\n",
    "\n",
    "df=pd.DataFrame(templi,columns=['ID', 'Count'])\n",
    "name=\"SS_caida0\"+'_'+str(size)\n",
    "df.to_csv(name+\".csv\",index=False)\n",
    "\n",
    "\n",
    "#====================result compare=============================\n",
    "path=\"..\\\\dataset\\\\\"\n",
    "groundtruth='caida_0_ground_truth.csv'\n",
    "final=name+\".csv\"\n",
    "\n",
    "grtruth=pd.read_csv(groundtruth)\n",
    "My_result=pd.read_csv(final)\n",
    "\n",
    "\n",
    "# precision\n",
    "gt_set=set(grtruth['Element'][:size])\n",
    "    # Top-size of ground truth\n",
    "my_set=set(My_result['ID'])\n",
    "precision=len(gt_set & my_set)/len(my_set)\n",
    "    # &: set 交集運算\n",
    "\n",
    "# ARE/AAE\n",
    "gt_li=grtruth.values.tolist()[:size]\n",
    "top_li=My_result.values.tolist()\n",
    "ID=[j[0] for j in gt_li]\n",
    "top_are=0\n",
    "top_aae=0\n",
    "tp=0\n",
    "fp=0\n",
    "for item in top_li:\n",
    "    if item[0] in ID:\n",
    "        index=ID.index(item[0])\n",
    "        tp+=1\n",
    "        top_are+=abs(gt_li[index][1]-item[1])/gt_li[index][1]\n",
    "        top_aae+=abs(gt_li[index][1]-item[1])\n",
    "    else:\n",
    "        fp+=1\n",
    "top_are=top_are/size\n",
    "top_aae=top_aae/size\n",
    "\n",
    "print(\"Find:{}, TP:{}, FP:{}\".format(len(gt_set & my_set),tp,fp))\n",
    "print(\"Precision: {:8.4f}\".format(precision))\n",
    "print(\"ARE: {:8.6f}\".format(top_are))\n",
    "print(\"AAE: {:8.6f}\".format(top_aae))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
