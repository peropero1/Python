{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=1024\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=2048\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=3072\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=4096\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=5120\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=6144\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=7168\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import Tools.Config as TC\n",
    "import Tools.Func as TF\n",
    "import Node.DS as DS\n",
    "import time\n",
    "import os\n",
    "\n",
    "from pympler import asizeof\n",
    "import re\n",
    "import pandas as pd\n",
    "dataset='caida'\n",
    "# =============================dataset path and file=============================\n",
    "filepath=r\"..\\..\\dataset\\caida\"\n",
    "pattern='\\w+.dat$'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(filepath)))    \n",
    "    # dataset file list\n",
    "\n",
    "gr_file_name='srcip\\caida_ground_truth.csv'\n",
    "gr_path=os.path.join(filepath,gr_file_name)\n",
    "    # ground truth path\n",
    "    \n",
    "# =============================Initialize=============================\n",
    "w=0\n",
    "d=0\n",
    "size=8192\n",
    "topk=1024\n",
    "TC.Set_default(w,d,size,topk)\n",
    "    # set width, depth, size of Sk, random seed of hash\n",
    "    # Config.width, Config.depth\n",
    "Top_dict=dict()\n",
    "\n",
    "#item_count=100\n",
    "# =============================Stream processing=============================\n",
    "start=time.time()\n",
    "for datafile in filelist[:]:\n",
    "    src_data=os.path.join(filepath,datafile)\n",
    "    with open(src_data,'rb') as file:\n",
    "         #以binary讀取，資料型態也為byte\n",
    "        while True:\n",
    "            e=file.read(13)\n",
    "            if len(e)<13:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                e=str(e[:4])\n",
    "                item=DS.Tail(e,1)\n",
    "                #item_count-=1\n",
    "                # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                if Top_dict.get(item.ID):\n",
    "                    # e in Top\n",
    "                    Top_dict[item.ID]+=1\n",
    "                else:\n",
    "                    if len(Top_dict)<TC.size:\n",
    "                        Top_dict[item.ID]=1\n",
    "                    else:\n",
    "                        min_ele = min(Top_dict, key=Top_dict.get)\n",
    "                            # find e_min\n",
    "                        Top_dict[item.ID]=Top_dict[min_ele]+1\n",
    "                            # update c_min\n",
    "                        Top_dict.pop(min_ele)\n",
    "                            # pop old min out\n",
    "end=time.time()\n",
    "\n",
    "# =============================Print and Plot result=============================\n",
    "Top_dict=dict(sorted(Top_dict.items(), key=lambda item: item[1],reverse=True))\n",
    "print(\"Top-{}\".format(TC.size))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "# Element-Precision\n",
    "tempdf=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "ss_result_dict=dict(tempdf[:TC.topk].values)\n",
    "tp_set,precision=TF.Get_precision(gr_path,ss_result_dict,TC.topk)\n",
    "    # Top-1024 in Top_dict compare to ground truth\n",
    "print(\"Precision: {:6.3f}\".format(precision))\n",
    "    \n",
    "# memory usage\n",
    "print(\"Top_dict with {} kbytes.\".format(asizeof.asizeof(Top_dict)/1024))\n",
    "\n",
    "# Count ARE/AAE\n",
    "startx=time.time()\n",
    "top_are,top_aae=TF.Get_ARE_AAE(gr_path,ss_result_dict,tp_set)\n",
    "print(\"Find:{}\".format(len(tp_set)))\n",
    "#print(\"{} item found in SS[{}] compare with true Top-{}\".format(len(tp_set),Config.size,topk))\n",
    "endx=time.time()\n",
    "\n",
    "print(\"Top_ARE: {:6.4f}\".format(top_are))\n",
    "print(\"Top_AAE: {:6.4f}\".format(top_aae))\n",
    "print(\"Estimate time:{:7.3f} seconds.\".format(endx-startx)) \n",
    "\n",
    "TF.Plot_topk_compare(gr_path,Top_dict,'Space Saving')\n",
    "\n",
    "# result to csv\n",
    "import pandas as pd\n",
    "\n",
    "path=\"..\\\\result\\\\SS\\\\\"+dataset+\"\\\\Top_\"+str(TC.size)\n",
    "filename='SS_'+str(size)+'_'+dataset+'.csv'\n",
    "df=pd.DataFrame(Top_dict.items(),columns=['Element','Count'])\n",
    "df['Element'] = df['Element'].astype(str)\n",
    "df.to_csv(os.path.join(path,filename),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
