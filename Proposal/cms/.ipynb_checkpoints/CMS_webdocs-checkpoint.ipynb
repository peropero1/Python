{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full version, counting and estimate frequency for all arriving elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-dacdb22b1182>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m                                 \u001b[0mTop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                                 \u001b[1;31m#rint(\"Top after pop:{}\\n\".format(Top))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                     \u001b[0mTop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mTop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;31m# print(topk[:20],len(topk))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-dacdb22b1182>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(Top)\u001b[0m\n\u001b[0;32m     62\u001b[0m                                 \u001b[0mTop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                                 \u001b[1;31m#rint(\"Top after pop:{}\\n\".format(Top))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                     \u001b[0mTop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mTop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;31m# print(topk[:20],len(topk))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# precision 約69~70%, top-256, cms:8*1034, execution time: 76xxx秒\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from probables import (CountMinSketch)\n",
    "import pandas as pd\n",
    "\n",
    "def find(e,Topk):\n",
    "    try:\n",
    "        index = [ele for ele,i in Topk].index(e)\n",
    "        return index\n",
    "    except:\n",
    "        index=-99\n",
    "    return index\n",
    "#==================== main =============================\n",
    "Top=[]\n",
    "w=1024\n",
    "d=8\n",
    "size=256\n",
    "# item_count=100\n",
    "cms = CountMinSketch(width=w, depth=d)\n",
    "\n",
    "#datapath='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "datapath='..\\dataset\\webdocs'\n",
    "# path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "pattern='out_.*'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(datapath)))\n",
    "\n",
    "start=time.time()\n",
    "for datafile in filelist:\n",
    "    src_data=os.path.join(datapath,datafile)\n",
    "    if os.path.exists(src_data):\n",
    "        with open(src_data,'r') as file:\n",
    "            while True:\n",
    "                e=file.readline().strip('\\n')\n",
    "                if not e:\n",
    "                    print('EOF')\n",
    "                    break\n",
    "                else:\n",
    "                    #item_count-=1\n",
    "                    #print(\"read {}th element: {}\".format(item_count,line[:10]))\n",
    "                    cms.add(e)\n",
    "                    count=cms.check(e)\n",
    "                    index=find(e,Top)\n",
    "                    if index >=0:\n",
    "                        Top[index][1]=count\n",
    "                    else:\n",
    "                        # e not in Top\n",
    "                        if len(Top)<size:\n",
    "                            # Top is not full\n",
    "                            Top.append([e,count])\n",
    "                            index=len(Top)-1\n",
    "                            #print(\"id of iindex:{}\".format(id(index)))\n",
    "                        else:\n",
    "                            # Top if full\n",
    "                            if count< Top[-1][1]:\n",
    "                                pass\n",
    "                            else:\n",
    "                                Top.append([e,count])\n",
    "                                Top=sorted(Top,key = lambda Top:Top[1],reverse=True)\n",
    "                                Top.pop()\n",
    "                                #rint(\"Top after pop:{}\\n\".format(Top))\n",
    "                    Top=sorted(Top,key = lambda Top:Top[1],reverse=True)\n",
    "        # print(topk[:20],len(topk))\n",
    "    else:\n",
    "        print(\"file doesn't exist\")\n",
    "        \n",
    "end=time.time()\n",
    "print(\"Total memory {3} bytes :Top-{0} with size {1} bytes+ CMS with size {2} bytes.\".format(len(Top),sys.getsizeof(Top),sys.getsizeof(cms._bins),sys.getsizeof(cms._bins)+sys.getsizeof(Top)))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "\n",
    "#====================Top to csv=============================\n",
    "templi=[[i[0],i[1]] for i in Top]\n",
    "df=pd.DataFrame(templi,columns=['ID', 'Count'])\n",
    "name=\"CMS_webdocs_Top-\"+str(size)+'_'+str(d)+'_'+str(w)+'.csv'\n",
    "df.to_csv(os.path.join('result',name),index=False)\n",
    "\n",
    "# ====================precision====================\n",
    "#gr_path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "gr_truth='..\\dataset\\webdocs'\n",
    "gr_file_name='webdocs_ground_truth.csv'\n",
    "grtruth=pd.read_csv(os.path.join(gr_truth,gr_file_name))\n",
    "    # ground truth of webdocs\n",
    "CMS_result=pd.read_csv(os.path.join('result',name))\n",
    "    # result of Top-k elements and estimated frequencies\n",
    "\n",
    "# precision\n",
    "gt_set=set(grtruth['Element'][:size])\n",
    "cms_set=set(CMS_result['ID'])\n",
    "precision=len(gt_set & cms_set)/len(cms_set)\n",
    "    # &: set 交集運算\n",
    "    # precision= tp/tp+fp=tp/size\n",
    "print(\"Precision: {}\".format(precision))\n",
    "\n",
    "# ====================ARE/AAE for Top and all====================\n",
    "gt_dict=dict(grtruth.values.tolist())\n",
    "top_are=0\n",
    "top_aae=0\n",
    "all_are=0\n",
    "all_aae=0\n",
    "tp=0\n",
    "fp=0\n",
    "\n",
    "read=0\n",
    "startx=time.time()\n",
    "for item in grtruth['Element']:\n",
    "    count=cms.check(str(item))\n",
    "    if read<size:\n",
    "        top_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "        top_aae+=abs(count-gt_dict[item])\n",
    "        read+=1\n",
    "        if item in cms_set:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    all_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "    all_aae+=abs(count-gt_dict[item])\n",
    "endx=time.time()\n",
    "\n",
    "distinct=len(gt_dict)\n",
    "top_are/=size\n",
    "all_are/=distinct\n",
    "all_aae/=distinct \n",
    "print(\"Top_ARE: {:8.6f}\".format(top_are))\n",
    "print(\"Top_AAE: {:8.3f}\".format(top_aae))\n",
    "print(\"all_ARE: {:8.6f}\".format(all_are))\n",
    "print(\"all_AAE: {:8.3f}\".format(all_aae))\n",
    "print(\"Estimate time:{:8.3f} seconds.\".format(endx-startx))\n",
    "\n",
    "# ====================Cover result into a dataframe====================\n",
    "sketch_size=str(d)+'*'+str(w)\n",
    "temp=sys.getsizeof(Top)+sys.getsizeof(cms._bins)\n",
    "memory_usage=str(temp)+' bytes ='+'Top:'+str(sys.getsizeof(Top))+'+ Sketch:'+str(sys.getsizeof(cms._bins))\n",
    "\n",
    "result_df=pd.DataFrame(columns=['Top-k',\n",
    "                                'Sketch',\n",
    "                                'Total memory',\n",
    "                                'Exe_time',\n",
    "                                'Find',\n",
    "                                'Precision',\n",
    "                                'ARE-Top',\n",
    "                                'AAE-Top',\n",
    "                                'ARE-all',\n",
    "                                'AAE-all'])\n",
    "output_dict={\n",
    "    'Top-k':size,\n",
    "    'Sketch':sketch_size,\n",
    "    'Total memory':memory_usage,\n",
    "    'Exe_time':float('{:8.3f}'.format(end-start)),\n",
    "    'Find':\"Find:{}, TP:{}, FP:{}\".format(len(gt_set & cms_set),tp,fp),\n",
    "    'Precision':float(\"{:8.4f}\".format(precision)),\n",
    "    'ARE-Top':float('{:8.6f}'.format(top_are)),\n",
    "    'AAE-Top':float('{:8.6f}'.format(top_aae)),\n",
    "    'ARE-all':float('{:8.6f}'.format(all_ARE)),\n",
    "    'AAE-all':float('{:8.6f}'.format(all_AAE))}\n",
    "\n",
    "result_df=result_df.append(output_dict,ignore_index=True)\n",
    "file=\"CMS_webdocs_result\"+'_'+str(size)+'_'+str(d)+'_'+str(w)+'_.csv'\n",
    "    # 程式執行結果供複製用\n",
    "result_df.to_csv(os.path.join(os.path.join(r'..\\result',file)),index=False)\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count and estimate after all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from probables import (CountMinSketch)\n",
    "import pandas as pd\n",
    "\n",
    "def find(e,Topk):\n",
    "    try:\n",
    "        index = [ele for ele,i in Topk].index(e)\n",
    "        return index\n",
    "    except:\n",
    "        index=-99\n",
    "    return index\n",
    "#==================== main =============================\n",
    "\n",
    "Top=[]\n",
    "w=1024\n",
    "d=8\n",
    "size=256\n",
    "# item_count=100\n",
    "cms = CountMinSketch(width=w, depth=d)\n",
    "\n",
    "datapath='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "# path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "pattern='out_.*'\n",
    "r=re.compile(pattern)\n",
    "filelist=list(filter(r.match,os.listdir(datapath)))\n",
    "\n",
    "start=time.time()\n",
    "for datafile in filelist[:1]:\n",
    "    src_data=os.path.join(datapath,datafile)\n",
    "    if os.path.exists(src_data):\n",
    "        with open(src_data,'r') as file:\n",
    "            while True:\n",
    "                e=file.readline().strip('\\n')\n",
    "                if not e:\n",
    "                    print('EOF')\n",
    "                    break\n",
    "                else:\n",
    "                    #item_count-=1\n",
    "                    #print(\"read {}th element: {}\".format(item_count,line[:10]))\n",
    "                    cms.add(e)\n",
    "                    '''\n",
    "                    count=cms.check(e)\n",
    "                    index=find(e,Top)\n",
    "                    if index >=0:\n",
    "                        Top[index][1]=count\n",
    "                    else:\n",
    "                        # e not in Top\n",
    "                        if len(Top)<size:\n",
    "                            # Top is not full\n",
    "                            Top.append([e,count])\n",
    "                            index=len(Top)-1\n",
    "                            #print(\"id of iindex:{}\".format(id(index)))\n",
    "                        else:\n",
    "                            # Top if full\n",
    "                            if count< Top[-1][1]:\n",
    "                                pass\n",
    "                            else:\n",
    "                                Top.append([e,count])\n",
    "                                Top=sorted(Top,key = lambda Top:Top[1],reverse=True)\n",
    "                                Top.pop()\n",
    "                                #rint(\"Top after pop:{}\\n\".format(Top))\n",
    "                    Top=sorted(Top,key = lambda Top:Top[1],reverse=True)                    \n",
    "                    '''\n",
    "        # print(topk[:20],len(topk))\n",
    "    else:\n",
    "        print(\"file doesn't exist\")\n",
    "end=time.time()\n",
    "\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))  \n",
    "print(\"Total memory {} bytes\".format(sys.getsizeof(cms._bins)))\n",
    "\n",
    "# ====================ARE/AAE for all====================\n",
    "\n",
    "gr_path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "gr_file_name='webdocs_ground_truth.csv'\n",
    "grtruth=pd.read_csv(os.path.join(gr_path,gr_file_name))\n",
    "gt_dict=dict(grtruth.values.tolist())\n",
    "top_are=0\n",
    "top_aae=0\n",
    "all_are=0\n",
    "all_aae=0\n",
    "\n",
    "read=0\n",
    "\n",
    "startx=time.time()\n",
    "for item in grtruth['Element']:\n",
    "    count=cms.check(str(item))    \n",
    "    if read<size:\n",
    "        # ARE/AAE of Top\n",
    "        top_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "        top_aae+=abs(count-gt_dict[item])\n",
    "        read+=1\n",
    "    # ARE/AAE of others\n",
    "    all_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "    all_aae+=abs(count-gt_dict[item])\n",
    "endx=time.time()\n",
    "\n",
    "distinct=len(gt_dict)\n",
    "top_are/=size\n",
    "all_are/=distinct\n",
    "all_aae/=distinct \n",
    "print(\"Top_ARE: {:8.6f}\".format(top_are))\n",
    "print(\"Top_AAE: {:8.3f}\".format(top_aae))\n",
    "print(\"all_ARE: {:8.6f}\".format(all_are))\n",
    "print(\"all_AAE: {:8.3f}\".format(all_aae))\n",
    "print(\"Estimate time:{:8.3f} seconds.\".format(endx-startx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
