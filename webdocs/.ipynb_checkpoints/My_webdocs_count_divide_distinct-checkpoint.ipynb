{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About webdocs\n",
    "- reading webdocs.dat ... [5267656 item(s), 1692082 transaction(s)]\n",
    "- sorting and reducing transactions ... [959755/1692082 transaction(s)]\n",
    "\n",
    "- Distinct element: 1535431\n",
    "- Number of incomming lines: 1692083\n",
    "- Top-10 frequent element and count: \n",
    "\n",
    "| Element | Count |\n",
    "| :----- | :----- |\n",
    "| 14525 | 11744 |\n",
    "| 6 8 22 49 76 81 122 126 140 146 147 149 150 16... |  2158 |\n",
    "| 1003 1699 2055 9941  | 1742 |\n",
    "| 8 24 60 124 146 157 171 172 220 260 395 419 42... |  1063 |\n",
    "| 60 84 119 122 124 146 157 168 171 220 258 290 ... |   783 |\n",
    "| 1 8 14 22 31 49 55 66 72 83 84 86 90 92 121 12... |   658 |\n",
    "| 1 8 14 22 49 81 88 122 140 158 220 255 310 312... |   546 |\n",
    "| 8 21 49 84 149 206 219 220 280 366 393 444 563... |   403 |\n",
    "| 49 87 206 274 308 339 389 506 516 523 524 595 ... |   376 |\n",
    "| 85 149 150 158 258 398 432 998 1114 2220 2558 ... |   375 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-256,Sketch:128*256\n",
      "Execution time:1024.985 seconds.\n",
      "Total memory 140456 bytes=Top:2216 bytes, Sketch:131072 bytes, Sketch_head:7168 bytes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spookyhash\n",
    "import mmh3\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import operator\n",
    "import hyperloglog\n",
    "import sys\n",
    "\n",
    "\n",
    "# ==========================data structure==========================\n",
    "class Node():\n",
    "    def __init__(self,count=0):\n",
    "        self.count=count\n",
    "    def add_count(self,count=1):\n",
    "        self.count+=count\n",
    "    def __str__(self):\n",
    "        return 'count: {}'.format(self.count)\n",
    "    def __repr__(self):\n",
    "        return ''\n",
    "\n",
    "class Head(Node):\n",
    "    def __init__(self,count=1):\n",
    "        super().__init__(count)\n",
    "        self.distinct = hyperloglog.HyperLogLog(0.01)\n",
    "        self.maxID=''\n",
    "    def __str__(self):\n",
    "        return '[total count: {}, distinct: {}, max: {}]'.format(self.count,len(self.distinct),self.maxID)\n",
    "    def __repr__(self):\n",
    "        return '[total count: {}, distinct: {}, max: {}]'.format(self.count,len(self.distinct),self.maxID)\n",
    "\n",
    "class Tail(Node):\n",
    "    def __init__(self,ID,count):\n",
    "        self.ID = ID\n",
    "        super().__init__(count)\n",
    "    def __str__(self):\n",
    "        return '[ID: {}, count: {}]'.format(self.ID,self.count)\n",
    "    def __repr__(self):\n",
    "        return '[ID: {}, count: {}]'.format(self.ID,self.count)\n",
    "\n",
    "# ==========================UpdateSk==========================\n",
    "def UpdateSk(element,Sk_head,Sk):\n",
    "    e_max=get_emax()\n",
    "    width,depth=get_width_depth()\n",
    "    col,row=position(element)\n",
    "        # col / row index of element \n",
    "    avg=0\n",
    "    #print(\"{} send to Sk[{}][{}]\".format(element,row,col))\n",
    "    # ==========================update sketch==========================\n",
    "    Sk_head[row].count+=element.count\n",
    "    Sk_head[row].distinct.add(element.ID)\n",
    "    Sk[row][col]+=1\n",
    "\n",
    "    Update_local_max(Sk_head[row],Sk[row],element,col)\n",
    "    Update_emax(Sk_head,Sk,row)\n",
    "\n",
    "'''\n",
    "    print(\"e_max:{}\".format(e_max))\n",
    "    for i in range(len(Sk)):\n",
    "        print(\"Sk[{}]:{},{}\".format(i,Sk_head[i],Sk[i]))\n",
    "    print('')\n",
    "'''\n",
    "\n",
    "\n",
    "# ==========================update local max==========================       \n",
    "def Update_local_max(head_item,element_list,element,column):\n",
    "    # local max need only 1 row\n",
    "    #print(\"In Update_local_max:\")\n",
    "    width,depth=get_width_depth()\n",
    "    if head_item.maxID=='':\n",
    "        head_item.maxID=element.ID\n",
    "    else:\n",
    "        # local_max_col=(mmh3.hash(head_item.maxID,signed=False))% ((width*numerator)//denominator)\n",
    "        local_max_col=(mmh3.hash(head_item.maxID,signed=False))% width\n",
    "        if element_list[local_max_col]<element_list[column]:\n",
    "            head_item.maxID=element.ID\n",
    "\n",
    "\n",
    "# ==========================update e_max==========================\n",
    "def Update_emax(head,sketch,sk_row):\n",
    "    e_max=get_emax()\n",
    "    local_max_col,local_max_row=position(Tail(head[sk_row].maxID,0))\n",
    "    if sketch[local_max_row][local_max_col]>e_max.count:\n",
    "        e_max.ID=head[sk_row].maxID\n",
    "        e_max.count=sketch[local_max_row][local_max_col]\n",
    "    \n",
    "    '''\n",
    "    # pass whole array\n",
    "    #print(\"In Update_emax:\")\n",
    "    e_max=get_emax()\n",
    "    for i in range(len(head)):\n",
    "        if head[i].maxID=='':\n",
    "            continue\n",
    "        else:\n",
    "            local_max_col,local_max_row=position(Tail(head[i].maxID,0))\n",
    "            if sketch[local_max_row][local_max_col]>e_max.count:\n",
    "                e_max.ID=head[i].maxID\n",
    "                e_max.count=sketch[local_max_row][local_max_col]   \n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "# ========================== BringBack=========================\n",
    "def BringBack(e_min,head,sketch):\n",
    "    # bring e_max back to Top\n",
    "    # e_min=e_max, e_max=Null, delete e_max.count in Sketch, send e_min into Sketch\n",
    "    e_max=get_emax()\n",
    "    temp=Tail(e_min.ID,e_min.count)\n",
    "    e_min.ID=e_max.ID\n",
    "    e_min.count=e_max.count\n",
    "    DeleteSk(e_max,head,sketch)\n",
    "    UpdateSk(temp,head,sketch)\n",
    "\n",
    "# ==========================DeleteSk=========================\n",
    "def DeleteSk(element,head,sketch):\n",
    "    # e_max in sketch: sketch[r][c]=0, total count-=sketch[row][col]\n",
    "    width,depth=get_width_depth()\n",
    "    col,row=position(element)\n",
    "    head[row].count-=e_max.count\n",
    "        # total_count-=element.count\n",
    "    sketch[row][col]=0\n",
    "    head[row].maxID=''\n",
    "    element.ID=\"\"\n",
    "    element.count=0\n",
    "# ==========================Tools=========================    \n",
    "def get_emax():\n",
    "    return e_max\n",
    "def get_width_depth():\n",
    "    return width,depth\n",
    "\n",
    "def find(e,element_list):\n",
    "    # return index of e in element_list\n",
    "    try:\n",
    "        index=[ele.ID for ele in element_list].index(e.ID)\n",
    "    except:\n",
    "        index=-99\n",
    "    return index\n",
    "\n",
    "def position(element):\n",
    "    width,depth=get_width_depth()\n",
    "    hash1=spookyhash.hash32(bytes(str(element.ID),encoding='utf-8'))\n",
    "        # input: byte\n",
    "        # output:unsigned- 32 bit int\n",
    "    hash2=mmh3.hash(element.ID, signed=False)\n",
    "        # input: str\n",
    "        # output: unsigned- 32 bit int\n",
    "    col=hash2 % width\n",
    "    row=hash1 % depth\n",
    "    return col,row \n",
    "\n",
    "# ==========================main=========================    \n",
    "\n",
    "#filename='webdocs.dat'\n",
    "filename=\"out_split_1.txt\"\n",
    "#filepath=r\"X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs\\\\\"\n",
    "filepath=r\"C:\\\\Users\\\\Pero\\\\python\\\\Python\\\\webdocs\\\\\"\n",
    "\n",
    "src_data=os.path.join(filepath,filename)\n",
    "depth=128\n",
    "width=256\n",
    "size=256\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "Sk_head=[Head(0) for j in range(depth)]\n",
    "Sketch=np.zeros((depth,width),dtype='int32')\n",
    "e_max=Tail('',0)\n",
    "Top=[]\n",
    "\n",
    "item_count=10\n",
    "income=0\n",
    "with open(src_data,'r') as file:\n",
    "    while True:\n",
    "        eli=file.readline().strip('\\n')\n",
    "        if not eli:\n",
    "            break\n",
    "        else:\n",
    "            #item_count-=1\n",
    "            #income+=1\n",
    "            #print(\"read {}-th transaction:{}\".format(income,eli))\n",
    "            item=Tail(eli,1)\n",
    "            index=find(item,Top)\n",
    "            if index<0:\n",
    "                if len(Top)<size:\n",
    "                    Top.append(item)\n",
    "                    index=len(Top)-1\n",
    "                else:\n",
    "                    UpdateSk(item,Sk_head,Sketch)\n",
    "            else:\n",
    "                Top[index].count+=1\n",
    "                if index==0 or Top[index].count< Top[index-1].count:\n",
    "                    pass\n",
    "                else:\n",
    "                    Top.sort(key=operator.attrgetter('count'),reverse=True)                \n",
    "            if e_max.count>Top[-1].count:\n",
    "                BringBack(Top[-1],Sk_head,Sketch)\n",
    "                Top.sort(key=operator.attrgetter('count'),reverse=True)\n",
    "            #print('Top after BringBack: \\n\\t{}'.format(Top)) \n",
    "\n",
    "end=time.time()\n",
    "print(\"Top-{},Sketch:{}*{}\".format(size,depth,width))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "print(\"Total memory {} bytes=\".format(sys.getsizeof(Top)+Sketch.nbytes+sys.getsizeof(Sk_head[0])*depth),end='')\n",
    "print(\"Top:{} bytes, Sketch:{} bytes, Sketch_head:{} bytes.\".format(sys.getsizeof(Top),Sketch.nbytes,sys.getsizeof(Sk_head[0])*depth))\n",
    "\n",
    "'''\n",
    "print(\"TOP[20]:\\n{}\".format(Top[:20]))\n",
    "print(\"e_max:{}\".format(e_max))\n",
    "for i in range(len(Sketch)):\n",
    "    print(\"Sk[{}]:{},{}\".format(i,Sk_head[i],Sketch[i]))\n",
    "print('')\n",
    "\n",
    "'''\n",
    "\n",
    "#====================Top to csv=============================\n",
    "templi=[[i.ID,i.count] for i in Top]\n",
    "df=pd.DataFrame(templi,columns=['ID', 'Count'])\n",
    "#path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs\\\\'\n",
    "path=r\"C:\\\\Users\\\\Pero\\\\Downloads\\\\\"\n",
    "name=\"My_webdocs\"+'_'+str(size)+'_'+str(depth)+'_'+str(width)\n",
    "final=name+\".csv\"\n",
    "df.to_csv(path+final,index=False)\n",
    "    #Top結果存到result\\\\kosarak\\\\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ID: 122, count: 75196], [ID: 8, count: 64761], [ID: 49, count: 57499], [ID: 516, count: 46460], [ID: 124, count: 45896], [ID: 121, count: 40718], [ID: 51, count: 40602], [ID: 171, count: 38763], [ID: 60, count: 35286], [ID: 878, count: 33070], [ID: 146, count: 32430], [ID: 84, count: 30468], [ID: 158, count: 30020], [ID: 150, count: 29246], [ID: 514, count: 29196], [ID: 22, count: 28344], [ID: 379, count: 27852], [ID: 476, count: 27089], [ID: 1, count: 26249], [ID: 308, count: 26111], [ID: 149, count: 26089], [ID: 81, count: 25714], [ID: 511, count: 25320], [ID: 524, count: 25221], [ID: 20, count: 25112], [ID: 9, count: 22758], [ID: 6, count: 22512], [ID: 603, count: 22502], [ID: 469, count: 22312], [ID: 142, count: 21620], [ID: 123, count: 21580], [ID: 461, count: 21354], [ID: 471, count: 21274], [ID: 76, count: 21064], [ID: 509, count: 21024], [ID: 14, count: 20897], [ID: 53, count: 20740], [ID: 879, count: 20652], [ID: 88, count: 20639], [ID: 590, count: 20200], [ID: 140, count: 20134], [ID: 376, count: 20081], [ID: 1051, count: 19657], [ID: 147, count: 19541], [ID: 72, count: 19214], [ID: 275, count: 19202], [ID: 863, count: 19186], [ID: 905, count: 19103], [ID: 422, count: 19083], [ID: 519, count: 19061], [ID: 448, count: 18966], [ID: 472, count: 18768], [ID: 873, count: 18674], [ID: 330, count: 18531], [ID: 485, count: 18450], [ID: 468, count: 18425], [ID: 338, count: 18052], [ID: 1095, count: 17776], [ID: 842, count: 17766], [ID: 208, count: 17581], [ID: 406, count: 17578], [ID: 48, count: 17568], [ID: 116, count: 17470], [ID: 313, count: 17147], [ID: 294, count: 17005], [ID: 521, count: 16889], [ID: 591, count: 16433], [ID: 444, count: 16424], [ID: 138, count: 16379], [ID: 355, count: 16376], [ID: 380, count: 16311], [ID: 1242, count: 16255], [ID: 361, count: 16149], [ID: 510, count: 16058], [ID: 21, count: 15992], [ID: 54, count: 15982], [ID: 112, count: 15889], [ID: 228, count: 15888], [ID: 319, count: 15813], [ID: 220, count: 15587], [ID: 506, count: 15551], [ID: 845, count: 15543], [ID: 369, count: 15374], [ID: 857, count: 15317], [ID: 621, count: 15116], [ID: 503, count: 15044], [ID: 475, count: 15003], [ID: 386, count: 14987], [ID: 340, count: 14986], [ID: 280, count: 14852], [ID: 805, count: 14722], [ID: 764, count: 14650], [ID: 370, count: 14510], [ID: 1158, count: 14481], [ID: 520, count: 14466], [ID: 459, count: 14353], [ID: 646, count: 14237], [ID: 455, count: 14122], [ID: 58, count: 14002], [ID: 185, count: 13904], [ID: 287, count: 13823], [ID: 40, count: 13590], [ID: 417, count: 13583], [ID: 1241, count: 13546], [ID: 1034, count: 13445], [ID: 1801, count: 13401], [ID: 684, count: 13315], [ID: 5576, count: 13247], [ID: 179, count: 13233], [ID: 55, count: 12926], [ID: 884, count: 12807], [ID: 470, count: 12800], [ID: 31, count: 12799], [ID: 402, count: 12766], [ID: 439, count: 12734], [ID: 588, count: 12679], [ID: 1793, count: 12646], [ID: 238, count: 12612], [ID: 934, count: 12612], [ID: 202, count: 12568], [ID: 401, count: 12566], [ID: 396, count: 12528], [ID: 389, count: 12457], [ID: 187, count: 12434], [ID: 90, count: 12420], [ID: 1098, count: 12420], [ID: 1345, count: 12336], [ID: 906, count: 12325], [ID: 30, count: 12236], [ID: 1003, count: 12153], [ID: 86, count: 12149], [ID: 325, count: 12136], [ID: 938, count: 12068], [ID: 42, count: 12051], [ID: 679, count: 12035], [ID: 1835, count: 12028], [ID: 561, count: 12026], [ID: 335, count: 11991], [ID: 1228, count: 11967], [ID: 221, count: 11958], [ID: 13, count: 11936], [ID: 504, count: 11922], [ID: 1029, count: 11888], [ID: 295, count: 11810], [ID: 860, count: 11765], [ID: 498, count: 11627], [ID: 1024, count: 11590], [ID: 1206, count: 11510], [ID: 536, count: 11492], [ID: 1203, count: 11483], [ID: 154, count: 11440], [ID: 998, count: 11430], [ID: 381, count: 11355], [ID: 595, count: 11255], [ID: 824, count: 11183], [ID: 1181, count: 11148], [ID: 1056, count: 11084], [ID: 407, count: 11047], [ID: 331, count: 11028], [ID: 838, count: 11009], [ID: 1088, count: 10958], [ID: 191, count: 10950], [ID: 66, count: 10908], [ID: 586, count: 10835], [ID: 512, count: 10833], [ID: 1458, count: 10766], [ID: 419, count: 10707], [ID: 1682, count: 10653], [ID: 870, count: 10588], [ID: 1977, count: 10582], [ID: 858, count: 10556], [ID: 563, count: 10556], [ID: 18, count: 10540], [ID: 1195, count: 10535], [ID: 659, count: 10518], [ID: 1236, count: 10492], [ID: 339, count: 10432], [ID: 157, count: 10401], [ID: 92, count: 10391], [ID: 1523, count: 10263], [ID: 259, count: 10153], [ID: 1077, count: 10150], [ID: 453, count: 10066], [ID: 377, count: 10018], [ID: 1659, count: 10014], [ID: 1244, count: 10002], [ID: 174, count: 9979], [ID: 109, count: 9921], [ID: 1112, count: 9864], [ID: 378, count: 9810], [ID: 692, count: 9794], [ID: 372, count: 9699], [ID: 490, count: 9611], [ID: 1144, count: 9576], [ID: 213, count: 9562], [ID: 560, count: 9513], [ID: 954, count: 9477], [ID: 718, count: 9402], [ID: 431, count: 9376], [ID: 596, count: 9328], [ID: 1208, count: 9318], [ID: 1172, count: 9295], [ID: 1285, count: 9277], [ID: 426, count: 9246], [ID: 1324, count: 9174], [ID: 1762, count: 9139], [ID: 484, count: 9138], [ID: 2355, count: 9103], [ID: 216, count: 9097], [ID: 473, count: 9063], [ID: 126, count: 9027], [ID: 543, count: 9023], [ID: 980, count: 9013], [ID: 1149, count: 8998], [ID: 2402, count: 8982], [ID: 493, count: 8962], [ID: 702, count: 8934], [ID: 425, count: 8929], [ID: 1136, count: 8912], [ID: 790, count: 8894], [ID: 332, count: 8829], [ID: 435, count: 8823], [ID: 241, count: 8799], [ID: 1049, count: 8788], [ID: 2154, count: 8738], [ID: 902, count: 8725], [ID: 979, count: 8709], [ID: 250, count: 8699], [ID: 1054, count: 8690], [ID: 486, count: 8685], [ID: 2633, count: 8685], [ID: 167, count: 8667], [ID: 1440, count: 8623], [ID: 393, count: 8601], [ID: 1566, count: 8490], [ID: 731, count: 8477], [ID: 217, count: 8474], [ID: 345, count: 8459], [ID: 794, count: 8391], [ID: 274, count: 8354], [ID: 629, count: 8353], [ID: 346, count: 8347], [ID: 1827, count: 8306], [ID: 206, count: 8288], [ID: 523, count: 8212], [ID: 312, count: 8173], [ID: 97, count: 8108], [ID: 1432, count: 8065], [ID: 853, count: 8008], [ID: 738, count: 7930], [ID: 1248, count: 7928], [ID: 177, count: 7921], [ID: 1621, count: 7907], [ID: 165, count: 7906], [ID: 1111, count: 7906], [ID: 1739, count: 7878]]\n"
     ]
    }
   ],
   "source": [
    "print(Top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#====================result compare=============================\n",
    "\n",
    "groundtruth='webdocs_ground_truth.csv'\n",
    "final=name+\".csv\"\n",
    "\n",
    "grtruth=pd.read_csv(os.path.join(path,groundtruth))\n",
    "My_result=pd.read_csv(os.path.join(path,final))\n",
    "\n",
    "# precision\n",
    "gt_set=set(grtruth['Element'][:size])\n",
    "    # Top-size of ground truth\n",
    "my_set=set(My_result['ID'])\n",
    "precision=len(gt_set & my_set)/len(my_set)\n",
    "    # &: set 交集運算\n",
    "print(\"Precision: {:8.4f}\".format(precision))\n",
    "\n",
    "gt_li=grtruth.values.tolist()[:size]\n",
    "top_li=My_result.values.tolist()\n",
    "ID=[j[0] for j in gt_li]\n",
    "top_are=0\n",
    "top_aae=0\n",
    "tp=0\n",
    "fp=0\n",
    "for item in top_li:\n",
    "    if item[0] in ID:\n",
    "        index=ID.index(item[0])\n",
    "        tp+=1\n",
    "        top_are+=abs(gt_li[index][1]-item[1])/gt_li[index][1]\n",
    "        top_aae+=abs(gt_li[index][1]-item[1])\n",
    "    else:\n",
    "        fp+=1\n",
    "top_are=top_are/size\n",
    "top_aae=top_aae/size\n",
    "# print(top_are,top_aae)\n",
    "\n",
    "# ====================ARE/AAE of all====================\n",
    "# ARE/AAE\n",
    "gt_dict=dict(grtruth.values.tolist())\n",
    "top_dict=dict(My_result.values.tolist())\n",
    "distinct=len(gt_dict)\n",
    "    # cardinality of all incoming elements\n",
    "row_cardinality=[len(i.distinct) for i in Sk_head]\n",
    "\n",
    "all_are_error=0\n",
    "all_aae_error=0\n",
    "\n",
    "for item in gt_dict:\n",
    "    if item in top_dict:\n",
    "        # item in Top\n",
    "        all_are_error+=abs(top_dict[item]-gt_dict[item])/gt_dict[item]\n",
    "        all_aae_error+=abs(top_dict[item]-gt_dict[item])\n",
    "    else:\n",
    "        # item in Sketch\n",
    "        item_col,item_row=position(Tail(item,1))\n",
    "        ratio=width/row_cardinality[item_row]\n",
    "        estimate=0\n",
    "        if Sketch[item_row][item_col]*ratio<1:\n",
    "            estimate=1\n",
    "        all_are_error+=abs(estimate-gt_dict[item])/gt_dict[item]\n",
    "            # 此dataset暫無count為0的情況\n",
    "        all_aae_error+=abs(estimate-gt_dict[item])\n",
    "\n",
    "all_ARE=all_are_error/distinct\n",
    "all_AAE=all_aae_error/distinct\n",
    "print(\"Find:{}, TP:{}, FP:{}\".format(len(gt_set & my_set),tp,fp))\n",
    "print(\"Top_ARE: {:8.6f}\".format(top_are))\n",
    "print(\"Top_AAE: {:8.6f}\".format(top_aae))\n",
    "print(\"all_ARE: {:8.6f}\".format(all_ARE))\n",
    "print(\"all_AAE: {:8.6f}\".format(all_AAE))\n",
    "\n",
    "# ====================Cover result into a dataframe====================\n",
    "sketch_size=str(depth)+'*'+str(width)\n",
    "temp=sys.getsizeof(Top)+Sketch.nbytes+sys.getsizeof(Sk_head[0])*depth\n",
    "memory_usage=str(temp)+' bytes ='+'Top:'+str(sys.getsizeof(Top))+'+ Sketch:'+str(Sketch.nbytes)+'+ Sk_head:'+str(sys.getsizeof(Sk_head[0])*depth)\n",
    "\n",
    "result_df=pd.DataFrame(columns=['Top-k',\n",
    "                                'Sketch',\n",
    "                                'Total memory',\n",
    "                                'Exe_time',\n",
    "                                'Find',\n",
    "                                'Precision',\n",
    "                                'ARE-Top',\n",
    "                                'AAE-Top',\n",
    "                                'ARE-all',\n",
    "                                'AAE-all'])\n",
    "output_dict={\n",
    "    'Top-k':size,\n",
    "    'Sketch':sketch_size,\n",
    "    'Total memory':memory_usage,\n",
    "    'Exe_time':float('{:.3f}'.format(end-start)),\n",
    "    'Find':\"Find:{}, TP:{}, FP:{}\".format(len(gt_set & my_set),tp,fp),\n",
    "    'Precision':float(\"{:8.4f}\".format(precision)),\n",
    "    'ARE-Top':float('{:8.6f}'.format(top_are)),\n",
    "    'AAE-Top':float('{:8.6f}'.format(top_aae)),\n",
    "    'ARE-all':float('{:8.6f}'.format(all_ARE)),\n",
    "    'AAE-all':float('{:8.6f}'.format(all_AAE))}\n",
    "\n",
    "result_df=result_df.append(output_dict,ignore_index=True)\n",
    "file=\"My_kosarak_distinct\"+'_'+str(size)+'_'+str(depth)+'_'+str(width)+'_.csv'\n",
    "result_df.to_csv(file,index=False)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs\\\\'\n",
    "groundtruth='webdocs_ground_truth.csv'\n",
    "xdf=pd.read_csv(path+groundtruth)\n",
    "y=xdf.groupby(by='Count')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=xdf.groupby(by='Count')\n",
    "z=y.size()\n",
    "    # only 139 different count for this dataset\n",
    "print(z.index.tolist())\n",
    "    # e出現的頻率\n",
    "print(z.values.tolist())\n",
    "    # 不同頻率出現的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
