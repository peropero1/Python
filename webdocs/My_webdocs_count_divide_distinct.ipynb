{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About webdocs\n",
    "- reading webdocs.dat ... [5267656 item(s), 1692082 transaction(s)]\n",
    "- sorting and reducing transactions ... [959755/1692082 transaction(s)]\n",
    "\n",
    "- Distinct element: 5267656\n",
    "- Number of incomming transactions: 1692082\n",
    "- Top-10 frequent element and count: \n",
    "\n",
    "| Element | Count |\n",
    "| :----- | :----- |\n",
    "|\t122\t|1429525|\n",
    "|\t8\t|1309694|\n",
    "|\t49\t|1178279|\n",
    "|\t124\t|887358|\n",
    "|\t516\t|858146|\n",
    "|\t171\t|793840|\n",
    "|\t51\t|787398|\n",
    "|\t121\t|726516|\n",
    "|\t878\t|677779|\n",
    "|\t150\t|677637|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-193a41e926c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m#print(\"read {}-th transaction:{}\".format(income,eli))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mitem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-193a41e926c0>\u001b[0m in \u001b[0;36mfind\u001b[1;34m(e, element_list)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mele\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melement_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import spookyhash\n",
    "import mmh3\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import operator\n",
    "import hyperloglog\n",
    "import sys\n",
    "\n",
    "\n",
    "# ==========================data structure==========================\n",
    "class Node():\n",
    "    def __init__(self,count=0):\n",
    "        self.count=count\n",
    "    def add_count(self,count=1):\n",
    "        self.count+=count\n",
    "    def __str__(self):\n",
    "        return 'count: {}'.format(self.count)\n",
    "    def __repr__(self):\n",
    "        return ''\n",
    "\n",
    "class Head(Node):\n",
    "    def __init__(self,count=1):\n",
    "        super().__init__(count)\n",
    "        self.distinct = hyperloglog.HyperLogLog(0.01)\n",
    "        self.maxID=''\n",
    "    def __str__(self):\n",
    "        return '[total count: {}, distinct: {}, max: {}]'.format(self.count,len(self.distinct),self.maxID)\n",
    "    def __repr__(self):\n",
    "        return '[total count: {}, distinct: {}, max: {}]'.format(self.count,len(self.distinct),self.maxID)\n",
    "\n",
    "class Tail(Node):\n",
    "    def __init__(self,ID,count):\n",
    "        self.ID = ID\n",
    "        super().__init__(count)\n",
    "    def __str__(self):\n",
    "        return '[ID: {}, count: {}]'.format(self.ID,self.count)\n",
    "    def __repr__(self):\n",
    "        return '[ID: {}, count: {}]'.format(self.ID,self.count)\n",
    "\n",
    "# ==========================UpdateSk==========================\n",
    "def UpdateSk(element,Sk_head,Sk):\n",
    "    e_max=get_emax()\n",
    "    width,depth=get_width_depth()\n",
    "    col,row=position(element)\n",
    "        # col / row index of element \n",
    "    avg=0\n",
    "    #print(\"{} send to Sk[{}][{}]\".format(element,row,col))\n",
    "    # ==========================update sketch==========================\n",
    "    Sk_head[row].count+=element.count\n",
    "    Sk_head[row].distinct.add(element.ID)\n",
    "    Sk[row][col]+=1\n",
    "\n",
    "    Update_local_max(Sk_head[row],Sk[row],element,col)\n",
    "    Update_emax(Sk_head,Sk,row)\n",
    "\n",
    "'''\n",
    "    print(\"e_max:{}\".format(e_max))\n",
    "    for i in range(len(Sk)):\n",
    "        print(\"Sk[{}]:{},{}\".format(i,Sk_head[i],Sk[i]))\n",
    "    print('')\n",
    "'''\n",
    "\n",
    "\n",
    "# ==========================update local max==========================       \n",
    "def Update_local_max(head_item,element_list,element,column):\n",
    "    # local max need only 1 row\n",
    "    #print(\"In Update_local_max:\")\n",
    "    width,depth=get_width_depth()\n",
    "    if head_item.maxID=='':\n",
    "        head_item.maxID=element.ID\n",
    "    else:\n",
    "        # local_max_col=(mmh3.hash(head_item.maxID,signed=False))% ((width*numerator)//denominator)\n",
    "        local_max_col=(mmh3.hash(head_item.maxID,signed=False))% width\n",
    "        if element_list[local_max_col]<element_list[column]:\n",
    "            head_item.maxID=element.ID\n",
    "\n",
    "\n",
    "# ==========================update e_max==========================\n",
    "def Update_emax(head,sketch,sk_row):\n",
    "    e_max=get_emax()\n",
    "    local_max_col,local_max_row=position(Tail(head[sk_row].maxID,0))\n",
    "    if sketch[local_max_row][local_max_col]>e_max.count:\n",
    "        e_max.ID=head[sk_row].maxID\n",
    "        e_max.count=sketch[local_max_row][local_max_col]\n",
    "    \n",
    "    '''\n",
    "    # pass whole array\n",
    "    #print(\"In Update_emax:\")\n",
    "    e_max=get_emax()\n",
    "    for i in range(len(head)):\n",
    "        if head[i].maxID=='':\n",
    "            continue\n",
    "        else:\n",
    "            local_max_col,local_max_row=position(Tail(head[i].maxID,0))\n",
    "            if sketch[local_max_row][local_max_col]>e_max.count:\n",
    "                e_max.ID=head[i].maxID\n",
    "                e_max.count=sketch[local_max_row][local_max_col]   \n",
    "    \n",
    "    '''\n",
    "\n",
    "\n",
    "# ========================== BringBack=========================\n",
    "def BringBack(e_min,head,sketch):\n",
    "    # bring e_max back to Top\n",
    "    # e_min=e_max, e_max=Null, delete e_max.count in Sketch, send e_min into Sketch\n",
    "    e_max=get_emax()\n",
    "    temp=Tail(e_min.ID,e_min.count)\n",
    "    e_min.ID=e_max.ID\n",
    "    e_min.count=e_max.count\n",
    "    DeleteSk(e_max,head,sketch)\n",
    "    UpdateSk(temp,head,sketch)\n",
    "\n",
    "# ==========================DeleteSk=========================\n",
    "def DeleteSk(element,head,sketch):\n",
    "    # e_max in sketch: sketch[r][c]=0, total count-=sketch[row][col]\n",
    "    width,depth=get_width_depth()\n",
    "    col,row=position(element)\n",
    "    head[row].count-=e_max.count\n",
    "        # total_count-=element.count\n",
    "    sketch[row][col]=0\n",
    "    head[row].maxID=''\n",
    "    element.ID=\"\"\n",
    "    element.count=0\n",
    "# ==========================Tools=========================    \n",
    "def get_emax():\n",
    "    return e_max\n",
    "def get_width_depth():\n",
    "    return width,depth\n",
    "\n",
    "def find(e,element_list):\n",
    "    # return index of e in element_list\n",
    "    try:\n",
    "        index=[ele.ID for ele in element_list].index(e.ID)\n",
    "    except:\n",
    "        index=-99\n",
    "    return index\n",
    "\n",
    "def position(element):\n",
    "    width,depth=get_width_depth()\n",
    "    hash1=spookyhash.hash32(bytes(str(element.ID),encoding='utf-8'))\n",
    "        # input: byte\n",
    "        # output:unsigned- 32 bit int\n",
    "    hash2=mmh3.hash(str(element.ID), signed=False)\n",
    "        # input: str\n",
    "        # output: unsigned- 32 bit int\n",
    "    col=hash2 % width\n",
    "    row=hash1 % depth\n",
    "    return col,row \n",
    "\n",
    "# ==========================main=========================    \n",
    "\n",
    "# path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "path='C:\\\\Users\\\\Pero\\\\python\\\\Python\\\\webdocs\\\\'\n",
    "pattern='out_.*'\n",
    "r=re.compile(pattern)\n",
    "fileli=list(filter(r.match,os.listdir(path)))\n",
    "    # filelist\n",
    "depth=128\n",
    "width=256\n",
    "size=512\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "Sk_head=[Head(0) for j in range(depth)]\n",
    "Sketch=np.zeros((depth,width),dtype='int32')\n",
    "e_max=Tail('',0)\n",
    "Top=[]\n",
    "\n",
    "item_count=100\n",
    "income=0\n",
    "for item in fileli:\n",
    "    with open(os.path.join(path,item),'r') as file:\n",
    "        while True:\n",
    "            e=file.readline().strip('\\n')\n",
    "            if not e:\n",
    "                break\n",
    "            else:\n",
    "                #item_count-=1\n",
    "                #income+=1\n",
    "                #print(\"read {}-th transaction:{}\".format(income,eli))            \n",
    "                item=Tail(e,1)\n",
    "                index=find(item,Top)\n",
    "                if index<0:\n",
    "                    if len(Top)<size:\n",
    "                        Top.append(item)\n",
    "                        index=len(Top)-1\n",
    "                    else:\n",
    "                        UpdateSk(item,Sk_head,Sketch)\n",
    "                else:\n",
    "                    Top[index].count+=1                \n",
    "                    if index==0 or Top[index].count< Top[index-1].count:\n",
    "                        pass\n",
    "                    else:\n",
    "                        Top.sort(key=operator.attrgetter('count'),reverse=True)                \n",
    "                if e_max.count>Top[-1].count:\n",
    "                    BringBack(Top[-1],Sk_head,Sketch)\n",
    "                    Top.sort(key=operator.attrgetter('count'),reverse=True)\n",
    "                    #print('Top after BringBack: \\n\\t{}'.format(Top)) \n",
    "\n",
    "end=time.time()\n",
    "print(\"Top-{},Sketch:{}*{}\".format(size,depth,width))\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))\n",
    "print(\"Total memory {} bytes=\".format(sys.getsizeof(Top)+Sketch.nbytes+sys.getsizeof(Sk_head[0])*depth),end='')\n",
    "print(\"Top:{} bytes, Sketch:{} bytes, Sketch_head:{} bytes.\".format(sys.getsizeof(Top),Sketch.nbytes,sys.getsizeof(Sk_head[0])*depth))\n",
    "\n",
    "'''\n",
    "print(\"TOP[20]:\\n{}\".format(Top[:20]))\n",
    "print(\"e_max:{}\".format(e_max))\n",
    "for i in range(len(Sketch)):\n",
    "    print(\"Sk[{}]:{},{}\".format(i,Sk_head[i],Sketch[i]))\n",
    "print('')\n",
    "\n",
    "'''\n",
    "\n",
    "#====================Top to csv=============================\n",
    "templi=[[i.ID,i.count] for i in Top]\n",
    "df=pd.DataFrame(templi,columns=['ID', 'Count'])\n",
    "# path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs\\\\'\n",
    "path='C:\\\\Users\\\\Pero\\\\python\\\\Python\\\\webdocs\\\\'\n",
    "groundtruth='webdocs_ground_truth.csv'\n",
    "name=\"My_webdocs_Top\"+'_'+str(size)+'_'+str(depth)+'_'+str(width)\n",
    "final=name+\".csv\"\n",
    "\n",
    "df.to_csv(os.path.join(path+final),index=False)\n",
    "    #儲存Top的結果\n",
    "\n",
    "#====================result compare=============================\n",
    "\n",
    "grtruth=pd.read_csv(os.path.join(path,groundtruth))\n",
    "My_result=pd.read_csv(os.path.join(path,final))\n",
    "\n",
    "# precision\n",
    "gt_set=set(grtruth['Element'][:size])\n",
    "    # Top-size of ground truth\n",
    "my_set=set(My_result['ID'])\n",
    "precision=len(gt_set & my_set)/len(my_set)\n",
    "    # &: set 交集運算\n",
    "print(\"Precision: {:8.4f}\".format(precision))\n",
    "\n",
    "gt_li=grtruth.values.tolist()[:size]\n",
    "top_li=My_result.values.tolist()\n",
    "ID=[j[0] for j in gt_li]\n",
    "top_are=0\n",
    "top_aae=0\n",
    "tp=0\n",
    "fp=0\n",
    "for item in top_li:\n",
    "    if item[0] in ID:\n",
    "        index=ID.index(item[0])\n",
    "        tp+=1\n",
    "        top_are+=abs(gt_li[index][1]-item[1])/gt_li[index][1]\n",
    "        top_aae+=abs(gt_li[index][1]-item[1])\n",
    "    else:\n",
    "        fp+=1\n",
    "top_are=top_are/size\n",
    "top_aae=top_aae/size\n",
    "# print(top_are,top_aae)\n",
    "\n",
    "# ====================ARE/AAE of all====================\n",
    "# ARE/AAE\n",
    "gt_dict=dict(grtruth.values.tolist())\n",
    "top_dict=dict(My_result.values.tolist())\n",
    "distinct=len(gt_dict)\n",
    "    # cardinality of all incoming elements\n",
    "row_cardinality=[len(i.distinct) for i in Sk_head]\n",
    "\n",
    "all_are_error=0\n",
    "all_aae_error=0\n",
    "\n",
    "for item in gt_dict:\n",
    "    if item in top_dict:\n",
    "        # item in Top\n",
    "        all_are_error+=abs(top_dict[item]-gt_dict[item])/gt_dict[item]\n",
    "        all_aae_error+=abs(top_dict[item]-gt_dict[item])\n",
    "    else:\n",
    "        # item in Sketch\n",
    "        item_col,item_row=position(Tail(item,1))\n",
    "        ratio=width/row_cardinality[item_row]\n",
    "        estimate=0\n",
    "        if Sketch[item_row][item_col]*ratio<1:\n",
    "            estimate=1\n",
    "        all_are_error+=abs(estimate-gt_dict[item])/gt_dict[item]\n",
    "            # 此dataset暫無count為0的情況\n",
    "        all_aae_error+=abs(estimate-gt_dict[item])\n",
    "\n",
    "all_ARE=all_are_error/distinct\n",
    "all_AAE=all_aae_error/distinct\n",
    "print(\"Find:{}, TP:{}, FP:{}\".format(len(gt_set & my_set),tp,fp))\n",
    "print(\"Top_ARE: {:8.6f}\".format(top_are))\n",
    "print(\"Top_AAE: {:8.6f}\".format(top_aae))\n",
    "print(\"all_ARE: {:8.6f}\".format(all_ARE))\n",
    "print(\"all_AAE: {:8.6f}\".format(all_AAE))\n",
    "\n",
    "# ====================Cover result into a dataframe====================\n",
    "sketch_size=str(depth)+'*'+str(width)\n",
    "temp=sys.getsizeof(Top)+Sketch.nbytes+sys.getsizeof(Sk_head[0])*depth\n",
    "memory_usage=str(temp)+' bytes ='+'Top:'+str(sys.getsizeof(Top))+'+ Sketch:'+str(Sketch.nbytes)+'+ Sk_head:'+str(sys.getsizeof(Sk_head[0])*depth)\n",
    "\n",
    "result_df=pd.DataFrame(columns=['Top-k',\n",
    "                                'Sketch',\n",
    "                                'Total memory',\n",
    "                                'Exe_time',\n",
    "                                'Find',\n",
    "                                'Precision',\n",
    "                                'ARE-Top',\n",
    "                                'AAE-Top',\n",
    "                                'ARE-all',\n",
    "                                'AAE-all'])\n",
    "output_dict={\n",
    "    'Top-k':size,\n",
    "    'Sketch':sketch_size,\n",
    "    'Total memory':memory_usage,\n",
    "    'Exe_time':float('{:.3f}'.format(end-start)),\n",
    "    'Find':\"Find:{}, TP:{}, FP:{}\".format(len(gt_set & my_set),tp,fp),\n",
    "    'Precision':float(\"{:8.4f}\".format(precision)),\n",
    "    'ARE-Top':float('{:8.6f}'.format(top_are)),\n",
    "    'AAE-Top':float('{:8.6f}'.format(top_aae)),\n",
    "    'ARE-all':float('{:8.6f}'.format(all_ARE)),\n",
    "    'AAE-all':float('{:8.6f}'.format(all_AAE))}\n",
    "\n",
    "result_df=result_df.append(output_dict,ignore_index=True)\n",
    "file=\"My_webdocs_distinct\"+'_'+str(size)+'_'+str(depth)+'_'+str(width)+'_.csv'\n",
    "    # 程式執行結果供複製用\n",
    "result_df.to_csv(file,index=False)\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs\\\\'\n",
    "groundtruth='webdocs_ground_truth.csv'\n",
    "xdf=pd.read_csv(path+groundtruth)\n",
    "y=xdf.groupby(by='Count')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=xdf.groupby(by='Count')\n",
    "z=y.size()\n",
    "    # only 139 different count for this dataset\n",
    "print(z.index.tolist())\n",
    "    # e出現的頻率\n",
    "print(z.values.tolist())\n",
    "    # 不同頻率出現的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
