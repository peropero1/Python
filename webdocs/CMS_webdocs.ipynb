{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count-Min sketch with built-in index search\n",
    "# Top-1024+ 4*1024 CMS\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from probables import (CountMinSketch)\n",
    "import pandas as pd\n",
    "\n",
    "def find(e,Topk):\n",
    "    try:\n",
    "        index = [ele for ele,i in Topk].index(e)\n",
    "        return index\n",
    "    except:\n",
    "        index=-99\n",
    "    return index\n",
    "\n",
    "start=time.time()\n",
    "# path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "pattern='out_.*'\n",
    "r=re.compile(pattern)\n",
    "fileli=list(filter(r.match,os.listdir(path)))\n",
    "\n",
    "topk=[]\n",
    "width=128\n",
    "depth=4\n",
    "size=256\n",
    "# item_count=10000\n",
    "cms = CountMinSketch(width=256, depth=4)\n",
    "for item in fileli[:1]:\n",
    "    if os.path.exists(item):\n",
    "        with open(os.path.join(path,item),'r') as file:\n",
    "            while True:\n",
    "                e=file.readline().strip('\\n')\n",
    "                if not e:\n",
    "                    print('EOF')\n",
    "                    break\n",
    "                else:\n",
    "                    #item_count-=1\n",
    "                    # print(\"read {}th element: {}\".format(item_count,element))\n",
    "                    cms.add(e)\n",
    "                    count=cms.check(e)\n",
    "                    if len(topk)==0:\n",
    "                        topk.append([e,count])\n",
    "                    else:\n",
    "                        index=find(line,topk)\n",
    "                        if index<0:\n",
    "                            #  element not in topk\n",
    "                            if len(topk)<size:\n",
    "                                topk.append([line,count])\n",
    "                            else:\n",
    "                                topk[-1][0]=line\n",
    "                                topk[-1][1]=count\n",
    "                        else:\n",
    "                            topk[index][1]=count\n",
    "                    topk=sorted(topk,key = lambda topk:topk[1],reverse=True)\n",
    "                    \n",
    "    end=time.time()\n",
    "    print(topk[:20],len(topk))\n",
    "    print(\"Total memory {3} bytes :Top-{0} with size {1} bytes+ CMS with size {2} bytes.\".format(len(topk),sys.getsizeof(topk),sys.getsizeof(cms._bins),sys.getsizeof(cms._bins)+sys.getsizeof(topk)))\n",
    "    print(\"Execution time:{} seconds.\".format(str(end-start)))\n",
    "else:\n",
    "    print(\"file doesn't exist\")\n",
    "\n",
    "'''\n",
    "#　conver Top into df  \n",
    "templi=[[i.ID,i.count] for i in Top]\n",
    "\n",
    "df=pd.DataFrame(templi,columns=['ID', 'Count'])\n",
    "df.to_csv(\"CM_kosarak_\"+str(size)+\".csv\",index=False)\n",
    "'''\n",
    "\n",
    "\n",
    "path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "#path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "df.to_csv(\"X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs\\\\\"+name+\".csv\",index=False)\n",
    "df.head(50)\n",
    "\n",
    "path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "#path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "groundtruth='webdocs_ground_truth.csv'\n",
    "final=name+\".csv\"\n",
    "\n",
    "grtruth=pd.read_csv(os.path.join(path,groundtruth),nrows=size)\n",
    "My_result1=pd.read_csv(os.path.join(path,final))\n",
    "\n",
    "gli = grtruth.values.tolist()\n",
    "li1= My_result1.values.tolist()\n",
    "\n",
    "tp=0\n",
    "fp=0\n",
    "find=0\n",
    "err=[]\n",
    "error=0\n",
    "for item in li1:\n",
    "    for element in gli:\n",
    "        if item[0]==element[0]:\n",
    "            # print(\"{},{} vs. {},{}\".format(item[0],item[1],element[0],element[1]))\n",
    "            find+=1\n",
    "            if item[1]==element[1]:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "                error+=abs(item[1]-element[1])/item[1]\n",
    "print(\"Find:{},TP:{},FP:{}\".format(find,tp,fp))\n",
    "#print(\"ARE:{}\".format(error/606770))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 只和Ground truth比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOF\n",
      "Execution time:25903.398 seconds.\n",
      "Total memory 262208 bytes\n",
      "Top_ARE: 1385.468580\n",
      "Top_AAE: 12760986.000\n",
      "all_ARE: 18365.730459\n",
      "all_AAE: 24642.706\n",
      "Estimate time: 879.574 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from probables import (CountMinSketch)\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def find(e,Topk):\n",
    "    try:\n",
    "        index = [ele for ele,i in Topk].index(e)\n",
    "        return index\n",
    "    except:\n",
    "        index=-99\n",
    "    return index\n",
    "\n",
    "start=time.time()\n",
    "# path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "pattern='out_.*'\n",
    "r=re.compile(pattern)\n",
    "fileli=list(filter(r.match,os.listdir(path)))\n",
    "\n",
    "topk=[]\n",
    "w=256\n",
    "d=128\n",
    "size=512\n",
    "#item_count=1000\n",
    "cms = CountMinSketch(width=w, depth=d)\n",
    "for item in fileli[:1]:\n",
    "    with open(os.path.join(path,item),'r') as file:\n",
    "        while True:\n",
    "            e=file.readline().strip('\\n')\n",
    "            if not e:\n",
    "                print('EOF')\n",
    "                break\n",
    "            else:\n",
    "                #item_count-=1\n",
    "                #print(\"read {}th element: {}\".format(item_count,e))\n",
    "                cms.add(str(e))\n",
    "                #count=cms.check(e)\n",
    "                '''\n",
    "                if len(topk)==0:\n",
    "                    topk.append([e,count])\n",
    "                else:\n",
    "                    index=find(line,topk)\n",
    "                    if index<0:\n",
    "                        #  element not in topk\n",
    "                        if len(topk)<size:\n",
    "                            topk.append([line,count])\n",
    "                        else:\n",
    "                            topk[-1][0]=line\n",
    "                            topk[-1][1]=count\n",
    "                    else:\n",
    "                        topk[index][1]=count\n",
    "                topk=sorted(topk,key = lambda topk:topk[1],reverse=True)\n",
    "                '''                    \n",
    "    #print(topk[:20],len(topk))\n",
    "    #print(\"Total memory {3} bytes :Top-{0} with size {1} bytes+ CMS with size {2} bytes.\".format(len(topk),sys.getsizeof(topk),sys.getsizeof(cms._bins),sys.getsizeof(cms._bins)+sys.getsizeof(topk)))\n",
    "\n",
    "end=time.time()\n",
    "\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(end-start))  \n",
    "print(\"Total memory {} bytes\".format(sys.getsizeof(cms._bins)))\n",
    "\n",
    "path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "# path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "groundtruth='webdocs_00_ground_truth.csv'\n",
    "grtruth=pd.read_csv(os.path.join(path,groundtruth))\n",
    "gt_dict=dict(grtruth.values.tolist())\n",
    "top_are=0\n",
    "top_aae=0\n",
    "all_are=0\n",
    "all_aae=0\n",
    "\n",
    "read=0\n",
    "startx=time.time()\n",
    "\n",
    "for item in grtruth['Element']:\n",
    "    count=cms.check(str(item))    \n",
    "    if read<size:\n",
    "        top_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "        top_aae+=abs(count-gt_dict[item])\n",
    "        read+=1\n",
    "    all_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "    all_aae+=abs(count-gt_dict[item])\n",
    "endx=time.time()\n",
    "distinct=len(gt_dict)\n",
    "top_are/=512\n",
    "all_are/=distinct\n",
    "all_aae/=distinct \n",
    "print(\"Top_ARE: {:8.6f}\".format(top_are))\n",
    "print(\"Top_AAE: {:8.3f}\".format(top_aae))\n",
    "print(\"all_ARE: {:8.6f}\".format(all_are))\n",
    "print(\"all_AAE: {:8.3f}\".format(all_aae))\n",
    "print(\"Estimate time:{:8.3f} seconds.\".format(endx-startx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 932.036 seconds.\n",
      "Top_ARE: 4.368602\n",
      "Top_AAE: 25432604.000\n",
      "all_ARE: 18365.730459\n",
      "all_AAE: 24642.706\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "path=r'C:\\Users\\Pero\\python\\Python\\webdocs'\n",
    "# path='X:\\\\NTU\\\\ML-sketch\\\\dataset\\\\Webpage\\\\webdocs'\n",
    "groundtruth='webdocs_00_ground_truth.csv'\n",
    "grtruth=pd.read_csv(os.path.join(path,groundtruth))\n",
    "gt_dict=dict(grtruth.values.tolist())\n",
    "top_are=0\n",
    "top_aae=0\n",
    "all_are=0\n",
    "all_aae=0\n",
    "\n",
    "read=0\n",
    "\n",
    "startx=time.time()\n",
    "for item in grtruth['Element']:\n",
    "    count=cms.check(str(item))    \n",
    "    if read<1024:\n",
    "        top_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "        top_aae+=abs(count-gt_dict[item])\n",
    "        read+=1\n",
    "    all_are+=abs(count-gt_dict[item])/gt_dict[item]\n",
    "    all_aae+=abs(count-gt_dict[item])\n",
    "endx=time.time()\n",
    "distinct=len(gt_dict)\n",
    "top_are/=1024\n",
    "all_are/=distinct\n",
    "all_aae/=distinct\n",
    "print(\"Execution time:{:8.3f} seconds.\".format(endx-startx))  \n",
    "print(\"Top_ARE: {:8.6f}\".format(top_are))\n",
    "print(\"Top_AAE: {:8.3f}\".format(top_aae))\n",
    "print(\"all_ARE: {:8.6f}\".format(all_are))\n",
    "print(\"all_AAE: {:8.3f}\".format(all_aae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
